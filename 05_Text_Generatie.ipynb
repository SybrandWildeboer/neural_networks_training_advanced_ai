{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# âœï¸ Tekst Generatie: Hoe AI tekst schrijft\n",
    "\n",
    "Hoe genereert ChatGPT tekst? In de kern voorspelt het steeds het **volgende woord** op basis van de voorgaande woorden.\n",
    "\n",
    "In dit notebook bouwen we zelf een heel simpel tekstgeneratiemodel om dit principe te begrijpen. We gebruiken **n-grammen**: het model kijkt naar de laatste N woorden en voorspelt het volgende.\n",
    "\n",
    "### Wat gaan we doen?\n",
    "1. Een tekst analyseren op woordpatronen\n",
    "2. Een simpel model bouwen dat tekst genereert\n",
    "3. Het verschil zien tussen een dom en slim model\n",
    "4. Begrijpen wat \"temperature\" doet\n",
    "\n",
    "---\n",
    "**Instructie:** Voer iedere cel uit met **Shift+Enter**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stap 1: Onze trainingstekst\n",
    "\n",
    "We gebruiken een stukje tekst als \"trainingsdata\". Hoe meer tekst, hoe beter het model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tekst = \"\"\"\n",
    "The cat sat on the mat. The cat looked at the bird. The bird sat on the tree.\n",
    "The dog chased the cat. The cat ran up the tree. The bird flew away from the tree.\n",
    "The dog sat on the mat. The dog looked at the cat in the tree.\n",
    "The cat jumped down from the tree. The cat sat on the mat again.\n",
    "The bird came back to the tree. The dog chased the bird. The bird flew over the dog.\n",
    "The cat watched the dog chase the bird. The dog gave up and sat on the mat.\n",
    "The cat and the dog sat on the mat together. The bird sang in the tree.\n",
    "The cat listened to the bird. The dog fell asleep on the mat.\n",
    "\"\"\".strip()\n",
    "\n",
    "# Splits in woorden\n",
    "woorden = tekst.lower().split()\n",
    "\n",
    "print(f\"Trainingstekst: {len(tekst)} karakters, {len(woorden)} woorden\")\n",
    "print(f\"Unieke woorden: {len(set(woorden))}\")\n",
    "print(f\"\\nEerste 30 woorden: {' '.join(woorden[:30])}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stap 2: Woordpatronen analyseren\n",
    "\n",
    "We kijken: na welke woorden volgen welke andere woorden? Dit noemen we **bigrammen** (paren van 2 woorden)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "# Tel voor elk woord welke woorden erna komen\n",
    "bigrammen = defaultdict(Counter)\n",
    "\n",
    "for i in range(len(woorden) - 1):\n",
    "    huidig = woorden[i]\n",
    "    volgend = woorden[i + 1]\n",
    "    bigrammen[huidig][volgend] += 1\n",
    "\n",
    "# Laten we een paar voorbeelden bekijken\n",
    "voorbeeld_woorden = ['the', 'cat', 'dog', 'sat', 'on']\n",
    "\n",
    "print(\"Na welk woord volgt wat?\")\n",
    "print(\"=\" * 50)\n",
    "for w in voorbeeld_woorden:\n",
    "    opties = bigrammen[w].most_common(5)\n",
    "    opties_str = ', '.join([f\"'{v}' ({n}x)\" for v, n in opties])\n",
    "    print(f\"  Na '{w}': {opties_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stap 3: Tekst genereren!\n",
    "\n",
    "Nu bouwen we een simpel model dat steeds het volgende woord kiest op basis van de waarschijnlijkheid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def genereer_tekst(startwoord, aantal_woorden=20, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Genereer tekst woord voor woord.\n",
    "    \n",
    "    temperature: \n",
    "      - laag (0.1) = voorspelbaar, kiest bijna altijd het meest waarschijnlijke woord\n",
    "      - hoog (2.0) = creatief/willekeurig, kiest vaker onverwachte woorden\n",
    "    \"\"\"\n",
    "    huidig = startwoord.lower()\n",
    "    resultaat = [huidig]\n",
    "    \n",
    "    for _ in range(aantal_woorden - 1):\n",
    "        if huidig not in bigrammen:\n",
    "            break\n",
    "        \n",
    "        # Haal de mogelijke volgende woorden op\n",
    "        opties = bigrammen[huidig]\n",
    "        volgende_woorden = list(opties.keys())\n",
    "        tellingen = np.array(list(opties.values()), dtype=float)\n",
    "        \n",
    "        # Pas temperature toe\n",
    "        tellingen = tellingen ** (1.0 / temperature)\n",
    "        kansen = tellingen / tellingen.sum()\n",
    "        \n",
    "        # Kies het volgende woord\n",
    "        huidig = np.random.choice(volgende_woorden, p=kansen)\n",
    "        resultaat.append(huidig)\n",
    "    \n",
    "    return ' '.join(resultaat)\n",
    "\n",
    "# Genereer tekst!\n",
    "print(\"Gegenereerde tekst:\")\n",
    "print(\"-\" * 50)\n",
    "for i in range(5):\n",
    "    print(f\"  {genereer_tekst('the', 15)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stap 4: Het effect van Temperature ðŸŒ¡ï¸\n",
    "\n",
    "Temperature is een instelling die ook ChatGPT en Claude gebruiken:\n",
    "- **Lage temperature** (0.1): het model kiest bijna altijd het meest waarschijnlijke woord â†’ voorspelbaar maar saai\n",
    "- **Hoge temperature** (2.0): het model kiest willekeuriger â†’ creatief maar soms onzin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Effect van temperature op tekstgeneratie:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for temp in [0.1, 0.5, 1.0, 2.0]:\n",
    "    print(f\"\\nðŸŒ¡ï¸ Temperature = {temp}:\")\n",
    "    for _ in range(3):\n",
    "        print(f\"  {genereer_tekst('the', 12, temperature=temp)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stap 5: Slimmer model â€” trigrammen\n",
    "\n",
    "Ons bigram-model kijkt maar naar **1 woord** terug. Echte taalmodellen kijken naar duizenden woorden terug.\n",
    "\n",
    "Laten we een iets slimmer model maken dat naar de **laatste 2 woorden** kijkt (trigrammen)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bouw een trigram-model (kijkt naar 2 woorden)\n",
    "trigrammen = defaultdict(Counter)\n",
    "\n",
    "for i in range(len(woorden) - 2):\n",
    "    context = (woorden[i], woorden[i + 1])  # De laatste 2 woorden\n",
    "    volgend = woorden[i + 2]\n",
    "    trigrammen[context][volgend] += 1\n",
    "\n",
    "def genereer_trigram(startwoorden, aantal_woorden=20, temperature=1.0):\n",
    "    w1, w2 = startwoorden[0].lower(), startwoorden[1].lower()\n",
    "    resultaat = [w1, w2]\n",
    "    \n",
    "    for _ in range(aantal_woorden - 2):\n",
    "        context = (w1, w2)\n",
    "        if context not in trigrammen:\n",
    "            break\n",
    "        \n",
    "        opties = trigrammen[context]\n",
    "        volgende_woorden = list(opties.keys())\n",
    "        tellingen = np.array(list(opties.values()), dtype=float)\n",
    "        tellingen = tellingen ** (1.0 / temperature)\n",
    "        kansen = tellingen / tellingen.sum()\n",
    "        \n",
    "        volgend = np.random.choice(volgende_woorden, p=kansen)\n",
    "        resultaat.append(volgend)\n",
    "        w1, w2 = w2, volgend\n",
    "    \n",
    "    return ' '.join(resultaat)\n",
    "\n",
    "print(\"Bigram-model (kijkt 1 woord terug):\")\n",
    "for _ in range(3):\n",
    "    print(f\"  {genereer_tekst('the', 15)}\")\n",
    "\n",
    "print(f\"\\nTrigram-model (kijkt 2 woorden terug):\")\n",
    "for _ in range(3):\n",
    "    print(f\"  {genereer_trigram(['the', 'cat'], 15)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stap 6: Vergelijking met echte taalmodellen\n",
    "\n",
    "Laten we de aanpak vergelijken:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vergelijking = {\n",
    "    'Eigenschap':           ['Ons bigram-model',     'Ons trigram-model',       'ChatGPT / Claude'],\n",
    "    'Kijkt terug':          ['1 woord',              '2 woorden',               '~100.000+ tokens'],\n",
    "    'Vocabulaire':          [f'{len(set(woorden))} woorden', f'{len(set(woorden))} woorden', '~100.000 tokens'],\n",
    "    'Trainingsdata':        [f'{len(woorden)} woorden', f'{len(woorden)} woorden', 'Miljarden woorden'],\n",
    "    'Begrijpt betekenis':   ['Nee',                  'Nee',                     'Ja (via embeddings)'],\n",
    "    'Parameters':           ['~100',                 '~500',                    '~175 miljard (GPT-4)'],\n",
    "}\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(vergelijking)\n",
    "df = df.set_index('Eigenschap')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Het kernprincipe is hetzelfde!\n",
    "\n",
    "Ondanks het enorme verschil in schaal, is het basisprincipe identiek:\n",
    "\n",
    "> **Gegeven de voorgaande context, wat is het meest waarschijnlijke volgende woord?**\n",
    "\n",
    "Het verschil zit in:\n",
    "- Hoeveel context het model kan verwerken\n",
    "- Dat echte modellen **embeddings** gebruiken (notebook 4) in plaats van losse woorden\n",
    "- Dat echte modellen **transformers** gebruiken om relaties tussen alle woorden tegelijk te begrijpen\n",
    "- De enorme hoeveelheid trainingsdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§ª Experimenteer zelf!\n",
    "\n",
    "Pas de trainingstekst aan en kijk wat er gebeurt. Probeer bijvoorbeeld een tekst over een ander onderwerp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probeer met je eigen tekst!\n",
    "eigen_tekst = \"\"\"\n",
    "The sun was shining bright. The sun made the flowers grow. The flowers were red and yellow.\n",
    "The rain came and the flowers drank the water. The sun came back and the flowers smiled.\n",
    "The wind blew the flowers gently. The flowers danced in the wind.\n",
    "The sun set behind the mountains. The flowers closed their petals.\n",
    "The moon rose and the stars appeared. The flowers slept until morning.\n",
    "The sun rose again and the flowers opened their petals.\n",
    "\"\"\".strip()\n",
    "\n",
    "# Herbouw het model met de nieuwe tekst\n",
    "eigen_woorden = eigen_tekst.lower().split()\n",
    "eigen_bigrammen = defaultdict(Counter)\n",
    "for i in range(len(eigen_woorden) - 1):\n",
    "    eigen_bigrammen[eigen_woorden[i]][eigen_woorden[i + 1]] += 1\n",
    "\n",
    "# Genereer\n",
    "for _ in range(5):\n",
    "    huidig = 'the'\n",
    "    resultaat = [huidig]\n",
    "    for _ in range(12):\n",
    "        if huidig in eigen_bigrammen:\n",
    "            opties = eigen_bigrammen[huidig]\n",
    "            volgend = random.choices(list(opties.keys()), weights=list(opties.values()))[0]\n",
    "            resultaat.append(volgend)\n",
    "            huidig = volgend\n",
    "        else:\n",
    "            break\n",
    "    print(' '.join(resultaat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
